#!/usr/bin/env python3
"""
Prompt Strategy Demonstration
=============================

This script demonstrates the practical impact of three prompt optimization strategies
by showing token counts, costs, and expected quality for different use cases.
"""

import json
from typing import Dict, List


def load_prompt_file(filepath: str) -> str:
    """Load prompt content from file"""
    try:
        with open(filepath, 'r') as f:
            return f.read()
    except FileNotFoundError:
        return f"FILE NOT FOUND: {filepath}"


def estimate_tokens(text: str) -> int:
    """Estimate token count"""
    return int(len(text.split()) / 0.75)


def calculate_cost(tokens: int, cost_per_1k: float = 0.002) -> float:
    """Calculate cost estimate"""
    return (tokens / 1000) * cost_per_1k


def demonstrate_strategies():
    """Demonstrate the three prompt strategies"""
    
    print("ğŸ¯ PROMPT STRATEGY DEMONSTRATION")
    print("=" * 35)
    print("Comparing Cost-Effective vs Sweet Spot vs Accuracy-Effective\n")
    
    strategies = [
        ("Cost-Effective", "prompts/strategies/cost_effective/PythonCodePrompt.txt"),
        ("Sweet Spot", "prompts/strategies/sweet_spot/PythonCodePrompt.txt"),
        ("Accuracy-Effective", "prompts/strategies/accuracy_effective/PythonCodePrompt.txt")
    ]
    
    use_cases = [
        ("Development Testing", 100),
        ("Production App", 1000),
        ("Enterprise Scale", 10000)
    ]
    
    print("ğŸ“Š STRATEGY COMPARISON:")
    print("-" * 25)
    
    for strategy_name, filepath in strategies:
        content = load_prompt_file(filepath)
        tokens = estimate_tokens(content)
        cost_per_prompt = calculate_cost(tokens)
        
        print(f"\n{strategy_name}:")
        print(f"  ğŸ“ Tokens: {tokens:,}")
        print(f"  ğŸ’° Cost per prompt: ${cost_per_prompt:.4f}")
        print(f"  ğŸ“ Length: {len(content.split())} words")
        
        if strategy_name == "Cost-Effective":
            print(f"  âš¡ Best for: High-volume, cost-sensitive applications")
        elif strategy_name == "Sweet Spot":
            print(f"  â­ Best for: General production use (RECOMMENDED)")
        else:
            print(f"  ğŸ¯ Best for: Critical applications requiring maximum quality")
    
    print(f"\n\nğŸ’° COST COMPARISON BY USE CASE:")
    print("=" * 35)
    
    for use_case, monthly_prompts in use_cases:
        print(f"\nğŸ“‹ {use_case} ({monthly_prompts:,} prompts/month):")
        
        for strategy_name, filepath in strategies:
            content = load_prompt_file(filepath)
            tokens = estimate_tokens(content)
            cost_per_prompt = calculate_cost(tokens)
            monthly_cost = cost_per_prompt * monthly_prompts
            annual_cost = monthly_cost * 12
            
            print(f"  {strategy_name}: ${monthly_cost:.2f}/month (${annual_cost:.2f}/year)")
    
    print(f"\n\nğŸ¯ STRATEGIC RECOMMENDATIONS:")
    print("=" * 30)
    
    recommendations = [
        ("ğŸš€ Startup/Development", "Cost-Effective", "Minimize costs during iteration"),
        ("ğŸ¢ Business Applications", "Sweet Spot", "Balance quality and cost"),
        ("âš¡ High-Volume Processing", "Cost-Effective", "Optimize for scale"),
        ("ğŸ”’ Critical Systems", "Accuracy-Effective", "Maximum quality required"),
        ("ğŸ‘¥ Client-Facing", "Sweet Spot", "Professional quality needed")
    ]
    
    for scenario, strategy, reason in recommendations:
        print(f"\n{scenario}:")
        print(f"  ğŸ¯ Use: {strategy}")
        print(f"  ğŸ’¡ Why: {reason}")
    
    print(f"\n\nâœ… SUMMARY:")
    print("=" * 10)
    print("â€¢ Cost-Effective: 75% cost reduction, basic quality")
    print("â€¢ Sweet Spot: Balanced approach, 83% quality at 2x cost")
    print("â€¢ Accuracy-Effective: Maximum quality, 10x cost")
    print(f"\nâ­ RECOMMENDED: Start with Sweet Spot for most applications")


if __name__ == "__main__":
    demonstrate_strategies() 